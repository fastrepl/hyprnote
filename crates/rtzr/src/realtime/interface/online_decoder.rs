// This file is @generated by prost-build.
/// The request message containing the user's name and how many greetings
/// they want.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DecoderRequest {
    /// The streaming request, which is either a streaming config or audio content.
    #[prost(oneof = "decoder_request::StreamingRequest", tags = "1, 2")]
    pub streaming_request: ::core::option::Option<decoder_request::StreamingRequest>,
}
/// Nested message and enum types in `DecoderRequest`.
pub mod decoder_request {
    /// The streaming request, which is either a streaming config or audio content.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum StreamingRequest {
        /// Provides information to the recognizer that specifies how to process the
        /// request. The first `StreamingRecognizeRequest` message must contain a
        /// `streaming_config`  message.
        #[prost(message, tag = "1")]
        StreamingConfig(super::DecoderConfig),
        /// The audio data to be recognized. Sequential chunks of audio data are sent
        /// in sequential `StreamingRecognizeRequest` messages. The first
        /// `StreamingRecognizeRequest` message must not contain `audio_content` data
        /// and all subsequent `StreamingRecognizeRequest` messages must contain
        /// `audio_content` data. The audio bytes must be encoded as specified in
        /// `RecognitionConfig`. Note: as with all bytes fields, proto buffers use a
        /// pure binary representation (not base64). See
        /// [content limits](<https://cloud.google.com/speech-to-text/quotas#content>).
        #[prost(bytes, tag = "2")]
        AudioContent(::prost::alloc::vec::Vec<u8>),
    }
}
/// A response message containing a greeting
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DecoderResponse {
    #[prost(bool, tag = "1")]
    pub error: bool,
    /// This repeated list contains zero or more results that
    /// correspond to consecutive portions of the audio currently being processed.
    /// It contains zero or one `is_final=true` result (the newly settled portion),
    /// followed by zero or more `is_final=false` results (the interim results).
    #[prost(message, repeated, tag = "2")]
    pub results: ::prost::alloc::vec::Vec<StreamingRecognitionResult>,
    /// Indicates the type of speech event.
    #[prost(enumeration = "decoder_response::SpeechEventType", tag = "4")]
    pub speech_event_type: i32,
}
/// Nested message and enum types in `DecoderResponse`.
pub mod decoder_response {
    /// Indicates the type of speech event.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum SpeechEventType {
        /// No speech event specified.
        SpeechEventUnspecified = 0,
        /// This event indicates that the server has detected the end of the user's
        /// speech utterance and expects no additional speech. Therefore, the server
        /// will not process additional audio (although it may subsequently return
        /// additional results). The client should stop sending additional audio
        /// data, half-close the gRPC connection, and wait for any additional results
        /// until the server closes the gRPC connection. This event is only sent if
        /// `single_utterance` was set to `true`, and is not used otherwise.
        EndOfSingleUtterance = 1,
        StartOfVad = 2,
        EndOfVad = 3,
    }
    impl SpeechEventType {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::SpeechEventUnspecified => "SPEECH_EVENT_UNSPECIFIED",
                Self::EndOfSingleUtterance => "END_OF_SINGLE_UTTERANCE",
                Self::StartOfVad => "START_OF_VAD",
                Self::EndOfVad => "END_OF_VAD",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "SPEECH_EVENT_UNSPECIFIED" => Some(Self::SpeechEventUnspecified),
                "END_OF_SINGLE_UTTERANCE" => Some(Self::EndOfSingleUtterance),
                "START_OF_VAD" => Some(Self::StartOfVad),
                "END_OF_VAD" => Some(Self::EndOfVad),
                _ => None,
            }
        }
    }
}
/// A streaming speech recognition result corresponding to a portion of the audio
/// that is currently being processed.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamingRecognitionResult {
    /// May contain one or more recognition hypotheses (up to the
    /// maximum specified in `max_alternatives`).
    /// These alternatives are ordered in terms of accuracy, with the top (first)
    /// alternative being the most probable, as ranked by the recognizer.
    #[prost(message, repeated, tag = "1")]
    pub alternatives: ::prost::alloc::vec::Vec<SpeechRecognitionAlternative>,
    /// If `false`, this `StreamingRecognitionResult` represents an
    /// interim result that may change. If `true`, this is the final time the
    /// speech service will return this particular `StreamingRecognitionResult`,
    /// the recognizer will not return any further hypotheses for this portion of
    /// the transcript and corresponding audio.
    #[prost(bool, tag = "2")]
    pub is_final: bool,
    /// An estimate of the likelihood that the recognizer will not
    /// change its guess about this interim result. Values range from 0.0
    /// (completely unstable) to 1.0 (completely stable).
    /// This field is only provided for interim results (`is_final=false`).
    /// The default of 0.0 is a sentinel value indicating `stability` was not set.
    #[prost(float, tag = "3")]
    pub stability: f32,
    /// duration of the audio.
    #[prost(int32, tag = "4")]
    pub duration: i32,
    /// Time offset of the start of this result relative to the
    /// beginning of the audio.
    #[prost(int32, tag = "5")]
    pub start_at: i32,
}
/// Alternative hypotheses (a.k.a. n-best list).
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SpeechRecognitionAlternative {
    /// Transcript text representing the words that the user spoke.
    #[prost(string, tag = "1")]
    pub text: ::prost::alloc::string::String,
    /// The confidence estimate between 0.0 and 1.0. A higher number
    /// indicates an estimated greater likelihood that the recognized words are
    /// correct. This field is set only for the top alternative of a non-streaming
    /// result or, of a streaming result where `is_final=true`.
    /// This field is not guaranteed to be accurate and users should not rely on it
    /// to be always provided.
    /// The default of 0.0 is a sentinel value indicating `confidence` was not set.
    #[prost(float, tag = "2")]
    pub confidence: f32,
    /// A list of word-specific information for each recognized word.
    /// Note: When `enable_speaker_diarization` is true, you will see all the words
    /// from the beginning of the audio.
    ///
    /// Word-specific information for recognized words.
    #[prost(message, repeated, tag = "3")]
    pub words: ::prost::alloc::vec::Vec<WordInfo>,
}
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct WordInfo {
    /// Time offset relative to the beginning of the audio,
    /// and corresponding to the start of the spoken word.
    /// This field is only set if `enable_word_time_offsets=true` and only
    /// in the top hypothesis.
    /// This is an experimental feature and the accuracy of the time offset can
    /// vary.
    #[prost(int64, tag = "1")]
    pub start_at: i64,
    /// Time offset relative to the beginning of the audio,
    /// and corresponding to the end of the spoken word.
    /// This field is only set if `enable_word_time_offsets=true` and only
    /// in the top hypothesis.
    /// This is an experimental feature and the accuracy of the time offset can
    /// vary.
    #[prost(int64, tag = "2")]
    pub duration: i64,
    /// The word corresponding to this set of information.
    #[prost(string, tag = "3")]
    pub text: ::prost::alloc::string::String,
    /// The confidence estimate between 0.0 and 1.0. A higher number
    /// indicates an estimated greater likelihood that the recognized words are
    /// correct. This field is set only for the top alternative of a non-streaming
    /// result or, of a streaming result where `is_final=true`.
    /// This field is not guaranteed to be accurate and users should not rely on it
    /// to be always provided.
    /// The default of 0.0 is a sentinel value indicating `confidence` was not set.
    #[prost(float, tag = "4")]
    pub confidence: f32,
    /// A distinct integer value is assigned for every speaker within
    /// the audio. This field specifies which one of those speakers was detected to
    /// have spoken this word. Value ranges from '1' to diarization_speaker_count.
    /// speaker_tag is set if enable_speaker_diarization = 'true' and only in the
    /// top alternative.
    #[prost(int32, tag = "5")]
    pub speaker_tag: i32,
}
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DecoderConfig {
    #[prost(int32, tag = "1")]
    pub sample_rate: i32,
    #[prost(enumeration = "decoder_config::AudioEncoding", tag = "2")]
    pub encoding: i32,
    /// Model name: 'default' for Korean, 'sommers_ja' for Japanese
    #[prost(string, optional, tag = "3")]
    pub model_name: ::core::option::Option<::prost::alloc::string::String>,
    #[prost(bool, optional, tag = "5")]
    pub use_itn: ::core::option::Option<bool>,
    #[prost(bool, optional, tag = "13")]
    pub use_disfluency_filter: ::core::option::Option<bool>,
    #[prost(bool, optional, tag = "14")]
    pub use_profanity_filter: ::core::option::Option<bool>,
    #[prost(message, optional, tag = "22")]
    pub stream_config: ::core::option::Option<RuntimeStreamConfig>,
    #[prost(string, repeated, tag = "23")]
    pub keywords: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
}
/// Nested message and enum types in `DecoderConfig`.
pub mod decoder_config {
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum AudioEncoding {
        /// Not specified.
        EncodingUnspecified = 0,
        /// Uncompressed 16-bit signed little-endian samples (Linear PCM).
        Linear16 = 1,
        Wav = 2,
        /// `FLAC` (Free Lossless Audio
        /// Codec) is the recommended encoding because it is
        /// lossless--therefore recognition is not compromised--and
        /// requires only about half the bandwidth of `LINEAR16`. `FLAC` stream
        /// encoding supports 16-bit and 24-bit samples, however, not all fields in
        /// `STREAMINFO` are supported.
        Flac = 3,
        /// 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
        Mulaw = 4,
        Alaw = 5,
        /// Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
        Amr = 6,
        /// Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
        AmrWb = 7,
        /// Opus encoded audio frames in Ogg container
        /// ([OggOpus](<https://wiki.xiph.org/OggOpus>)).
        /// `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
        OggOpus = 8,
        /// Opus encoded audio frames without container
        Opus = 9,
    }
    impl AudioEncoding {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::EncodingUnspecified => "ENCODING_UNSPECIFIED",
                Self::Linear16 => "LINEAR16",
                Self::Wav => "WAV",
                Self::Flac => "FLAC",
                Self::Mulaw => "MULAW",
                Self::Alaw => "ALAW",
                Self::Amr => "AMR",
                Self::AmrWb => "AMR_WB",
                Self::OggOpus => "OGG_OPUS",
                Self::Opus => "OPUS",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "ENCODING_UNSPECIFIED" => Some(Self::EncodingUnspecified),
                "LINEAR16" => Some(Self::Linear16),
                "WAV" => Some(Self::Wav),
                "FLAC" => Some(Self::Flac),
                "MULAW" => Some(Self::Mulaw),
                "ALAW" => Some(Self::Alaw),
                "AMR" => Some(Self::Amr),
                "AMR_WB" => Some(Self::AmrWb),
                "OGG_OPUS" => Some(Self::OggOpus),
                "OPUS" => Some(Self::Opus),
                _ => None,
            }
        }
    }
}
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct RuntimeStreamConfig {
    /// The default value for max_utter_duration is 12 seconds.
    /// This parameter sets the maximum length of a single utterance.
    /// If an utterance exceeds 12 seconds without any silence, it is divided into separate utterances.
    #[prost(int32, optional, tag = "1")]
    pub max_utter_duration: ::core::option::Option<i32>,
    /// The default value for epd_time is 0.5 seconds.
    /// If a silence period lasts for more than 0.5 seconds, the final STT result is returned.
    /// For voice bots, it is recommended to set a duration longer than 0.5 seconds.
    /// The recommended value range is between 0.5 and 1.0 seconds.
    #[prost(float, optional, tag = "3")]
    pub epd_time: ::core::option::Option<f32>,
}
/// Generated client implementations.
pub mod online_decoder_client {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value
    )]
    use tonic::codegen::http::Uri;
    use tonic::codegen::*;
    /// The greeting service definition.
    #[derive(Debug, Clone)]
    pub struct OnlineDecoderClient<T> {
        inner: tonic::client::Grpc<T>,
    }
    impl OnlineDecoderClient<tonic::transport::Channel> {
        /// Attempt to create a new client by connecting to a given endpoint.
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }
    impl<T> OnlineDecoderClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::BoxBody>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + std::marker::Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + std::marker::Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }
        pub fn with_origin(inner: T, origin: Uri) -> Self {
            let inner = tonic::client::Grpc::with_origin(inner, origin);
            Self { inner }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> OnlineDecoderClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::BoxBody>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::BoxBody>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<http::Request<tonic::body::BoxBody>>>::Error:
                Into<StdError> + std::marker::Send + std::marker::Sync,
        {
            OnlineDecoderClient::new(InterceptedService::new(inner, interceptor))
        }
        /// Compress requests with the given encoding.
        ///
        /// This requires the server to support it otherwise it might respond with an
        /// error.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.send_compressed(encoding);
            self
        }
        /// Enable decompressing responses.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.accept_compressed(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_decoding_message_size(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_encoding_message_size(limit);
            self
        }
        /// Sends multiple greetings
        pub async fn decode(
            &mut self,
            request: impl tonic::IntoStreamingRequest<Message = super::DecoderRequest>,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::DecoderResponse>>,
            tonic::Status,
        > {
            self.inner.ready().await.map_err(|e| {
                tonic::Status::unknown(format!("Service was not ready: {}", e.into()))
            })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static("/online_decoder.OnlineDecoder/Decode");
            let mut req = request.into_streaming_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("online_decoder.OnlineDecoder", "Decode"));
            self.inner.streaming(req, path, codec).await
        }
    }
}
