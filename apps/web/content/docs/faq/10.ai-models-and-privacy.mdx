---
title: "AI Models & Data Privacy"
section: "FAQ"
description: "Information about the AI models used in Char and how your data is handled."
---

## What AI models does Char use?

Char uses two types of AI models: speech-to-text (STT) models for transcription and large language models (LLMs) for generating summaries and notes.

### Speech-to-Text Models

Char supports multiple cloud-based STT providers for transcription. See the cloud providers section below for details. For local STT models and manual download instructions, see [Local Models](/docs/developers/local-models#speech-to-text-stt).

### Large Language Models

Char offers multiple options for AI features like summaries and note generation:

**Pro Curated Models** - Subscribe to Pro for access to curated cloud AI models that work out of the box with no configuration required.

**BYOK (Bring Your Own Key)** - Enter your own API key for OpenAI, Anthropic, Google, or Mistral if you want to use a specific provider.

**Local Models** - Run models locally using [LM Studio](https://lmstudio.ai) or [Ollama](https://ollama.com) for maximum privacy.

**Recommended local models:**

**Gemma** - Google's open-source language model family, available in various sizes. Great balance of quality and performance.

**Qwen** - Alibaba's open-source language model with strong multilingual capabilities.

See our [Local LLM Setup guide](/docs/faq/local-llm-setup) for instructions on configuring LM Studio or Ollama with Char. Pro users can also access curated cloud transcription and AI models - see [Better Transcription](/docs/pro/better-transcription) and [Cloud Services](/docs/pro/cloud).

## Does my audio data leave my device?

When using cloud-based transcription, your audio is sent to the selected STT provider for processing. See the cloud providers section below for details on each provider's data practices.

Your recordings are stored locally on your device. Transcripts and notes remain on your computer unless you explicitly choose to use cloud AI features.

## What cloud transcription providers does Char support?

When cloud transcription is enabled, Char can use the following providers:

**Deepgram** - Real-time speech recognition with support for 30+ languages. [Privacy Policy](https://deepgram.com/privacy)

**AssemblyAI** - Speech-to-text with speaker diarization. [Privacy Policy](https://www.assemblyai.com/legal/privacy-policy)

**Soniox** - High-accuracy transcription with support for 70+ languages. [Privacy Policy](https://soniox.com/privacy)

**Fireworks AI** - Fast inference for Whisper models. [Privacy Policy](https://fireworks.ai/privacy-policy)

**Gladia** - Real-time transcription service. [Privacy Policy](https://www.gladia.io/privacy-policy)

**OpenAI** - Whisper API for transcription. [Privacy Policy](https://openai.com/policies/privacy-policy)

## How is my data handled by cloud providers?

When using cloud transcription, your audio is sent to the selected provider for processing. Each provider has different data retention and privacy policies:

Most providers process audio in real-time and do not retain your data after transcription is complete. However, we recommend reviewing each provider's privacy policy for specific details about data handling, retention periods, and security measures.

Char Pro users who use cloud transcription through our proxy benefit from our agreements with these providers, which include data processing terms designed to protect your privacy.

## Can I use Char completely offline?

Char can record audio offline, but transcription and AI features require an internet connection when using cloud providers. If you run a local LLM server (via LM Studio or Ollama), you can generate summaries offline after transcription is complete.

## Does Char train AI models on my data?

No. Char does not use your recordings, transcripts, or notes to train AI models. When using cloud providers, your data is processed according to their respective privacy policies, but Char itself does not collect or use your data for training purposes.

## How do I ensure maximum privacy?

For maximum privacy:

1. Use a local LLM server (LM Studio or Ollama) for AI features instead of cloud providers
2. Keep your recordings stored locally on your device
3. Review the privacy policies of your chosen STT provider
4. Review your settings in Settings > Intelligence

When using local LLM servers, your notes and summaries are generated on your device without being sent to external servers. Learn more about our local-first philosophy in [Why Local-First?](/docs/about/why-local-first)
